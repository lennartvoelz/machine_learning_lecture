{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gkOUTDGDl9-u",
        "FwMsIRJyi0HH",
        "8qpK5D5Li0HM",
        "si_nJ7oii0HN",
        "xz-LKCXQi0IZ",
        "0L-IZu_pi0KL",
        "qKUJP3isi0Kb",
        "PiE7DOodi0Kq",
        "cMY5bYMCi0K-"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkOUTDGDl9-u"
      },
      "source": [
        "# Preface\n",
        "If you are new to Colab, please familiarize yourself with it by starting with the [introduction](https://colab.research.google.com/notebooks/intro.ipynb) and then working yourself through a [small tutorial](https://colab.research.google.com/drive/1umhPVtUWH8yHD2l9A_G4fdttmgmSgC0Q).\n",
        "\n",
        "Please, always save a copy of the notebook on your google drive before you start working and only edit that one. In addition, always switch the runtime to `python 3` and for most exercises it is recommended to switch also to a GPU runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwMsIRJyi0HH"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# Exercise 1 - Machine Learning Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9jK7Fyti0HK"
      },
      "source": [
        "In the first part of this exercise we will will apply linear regression to a dataset of brain properties. In the second part we will apply logistic regresseion to classify different types of iris flowers.\n",
        "\n",
        "This exercise is based on [\"Learning scikit-learn -- An Introduction to Machine Learning in Python @ PyData Chicago 2016\"](https://github.com/rasbt/pydata-chicago2016-ml-tutorial)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZN4NFD2pQqU"
      },
      "source": [
        "Before we start we need to download the two datasets named \"dataset_brain.txt\" and \"dataset_iris.txt\" from a shared google drive to the virtual machine of colab or our local machine so we will have it available:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO3MgjiiPQN_"
      },
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1W7s11mAK3PByOJIxPRpr1cIGhxsriI4c'\n",
        "output = 'dataset_brain.txt'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1lBQ55AHVbX29bEMNfLOunOE5PwYAKDpg'\n",
        "output = 'dataset_iris.txt'\n",
        "gdown.download(url, output, quiet=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElMjTT2-tFLA"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qpK5D5Li0HM"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "* [1 Linear Regression](#2-Linear-Regression)\n",
        "    * [Loading the dataset](#Loading-the-dataset)\n",
        "    * [Preparing the dataset](#Preparing-the-dataset)\n",
        "    * [Fitting the model](#Fitting-the-model)\n",
        "    * [Evaluating the model](#Evaluating-the-model)\n",
        "* [2 Classification](#3-Introduction-to-Classification)\n",
        "    * [The Iris dataset](#The-Iris-dataset)\n",
        "    * [Class label encoding](#Class-label-encoding)\n",
        "    * [Scikit-learn's in-build datasets](#Scikit-learn's-in-build-datasets)\n",
        "    * [Test/train splits](#Test/train-splits)\n",
        "    * [Logistic Regression](#Logistic-Regression)\n",
        "    * [K-Nearest Neighbors](#K-Nearest-Neighbors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si_nJ7oii0HN"
      },
      "source": [
        "# 1  Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0SAF0Svi0HP"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "861PYjzQi0HQ"
      },
      "source": [
        "We will use a dataset of an old publication which studied the relation of the brain weight to the head size for different gender and age ranges.\n",
        "\n",
        "Source: R.J. Gladstone (1905). \"A Study of the Relations of the Brain to\n",
        "to the Size of the Head\", Biometrika, Vol. 4, pp105-123\n",
        "\n",
        "The dataset is stored in a file called\n",
        "**`dataset_brain.txt`**\n",
        "\n",
        "Description: Brain weight (grams) and head size (cubic cm) for 237 adults classified by gender and age group.\n",
        "\n",
        "Variables/Columns\n",
        "- Gender (`1`=Male, `2`=Female)\n",
        "- Age Range (`1`=20-46, `2`=46+)\n",
        "- Head size (cm$^3$)\n",
        "- Brain weight (grams)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imAPhwhMi0HS"
      },
      "source": [
        "### Task 1: Print the first 30 lines of the dataset and inspect it\n",
        "*hints*\n",
        "- use `open(\"path/to/file\")`\n",
        "- `readlines` is a useful method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNzS7PKii0HT"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1T5qH4Di0Ha"
      },
      "source": [
        "We will use [**`pandas`**](https://pandas.pydata.org/pandas-docs/stable/) to read in the dataset.\n",
        "\n",
        "\n",
        "> pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language. It is already well on its way toward this goal. (quoted from web page)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuqqSLhji0Hb"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyjamOiqi0Hg"
      },
      "source": [
        "The file contains 'comma separated values' (CSV) and we will use pandas [**`DataFrame`**](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame) to handle the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4D3CW5Yi0Hh"
      },
      "source": [
        "df = pd.read_csv('dataset_brain.txt',\n",
        "                 encoding='utf-8',\n",
        "                 comment='#',\n",
        "                 sep='\\s+')\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRRBYn4kTYYK"
      },
      "source": [
        "*additional comments:*\n",
        "\n",
        "The cell above reads a text file with csv ending from the disk and converts it to a data frame. The parameter `comment` specifies which lines in the file will not be converted to data entries, `sep` specifies how data entries are separated. `\\s+` is a regular expression that matches one or more blanks or tabs between data entries. *sep* needs to be chosen according to your data format and could be other regular expressions or separating characters  like `;,\\t` (tab only), ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfJ5Axi4i0Hm"
      },
      "source": [
        "Let's look at the relation of the brain weight to the head size by plotting them in a 2D scatter plot. We will use [**`matplotlib`**](https://matplotlib.org/) for that.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6-g6ovui0Ho"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyJ62gpQi0Ht"
      },
      "source": [
        "We can call the columns of the pandas DataFrame simply by using the keys."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W3_kEnJi0Hv"
      },
      "source": [
        "plt.scatter(df['head-size'], df['brain-weight'])\n",
        "plt.xlabel('Head size (cm^3)')\n",
        "plt.ylabel('Brain weight (grams)');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0L-vzmUi0Hz"
      },
      "source": [
        "## Preparing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rFrZVFOi0H1"
      },
      "source": [
        "In order to use the dataset, we need to retrieve a [**`numpy`**](http://www.numpy.org/) array containing only the values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS9kVHRLi0H2"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED-d8jcji0H6"
      },
      "source": [
        "y = df['brain-weight'].values\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeXuEZ-Ii0H_"
      },
      "source": [
        "How many data points do we have?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70J6Vr6Vi0IA"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRW3XMYAi0IE"
      },
      "source": [
        "The same with the head size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl9IbCmRi0IG"
      },
      "source": [
        "X = df['head-size'].values\n",
        "print(X)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItZcS8Z8i0IM"
      },
      "source": [
        "In all machine learning frameworks like *scikit-learn*, *tensorflow*, *keras*, ..., it is a convention that the first data dimension depicts the number of samples, the second one the number of features. Our array has currently only one dimension. We have 237 samples, each containing only one feature value. To comply with the convention, we would like to have n arrays containing one value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwzcYpNji0IN"
      },
      "source": [
        "X = X[:, None]\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRhY9EfSUhMr"
      },
      "source": [
        "Alternatively you can use `X = X.reshape(len(X), 1)`\n",
        "or `X = X.reshape(-1, 1)` if you know that you have only one feature, but you are not sure how many values you have. Each *reshape* call can have up to one *-1* in it. This axis will then be determined by the other entries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_OnTSni0IS"
      },
      "source": [
        "We will use the machine learning tool and library [**`scikit-learn`**](http://scikit-learn.org/stable/) in the following.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUKgZ7Z7i0IU"
      },
      "source": [
        "A very useful functionality of scikit learn is to easily split the dataset into training and testing dataset. The dataset is split randomly with seed 123 and the test size is 30%, train size 70%:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOwNPjK9i0IV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fie3Ct6UtPZ"
      },
      "source": [
        "*additional comments:*\n",
        "\n",
        " using a seed for randomization results in getting the same random numbers for each call. In this example, we would always get the same test-train-split. This may seem like a mistake at first but is surprisingly useful for **testing your code** as you know that changes in the result do not come from a different randomization*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz-LKCXQi0IZ"
      },
      "source": [
        "### Task 2: Plot the training and testing dataset separately again in a 2D scatter plot including axis label. Use different colors (option [`c`(olor)`='blue'`](https://matplotlib.org/api/colors_api.html)) and different marker (option [`marker='o'`](https://matplotlib.org/api/markers_api.html))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXO36Xvoi0Ia",
        "scrolled": true
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj1ae2Lni0Ie"
      },
      "source": [
        "## Fitting the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TlDuvcPi0If"
      },
      "source": [
        "We would like to fit the training data now using the [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) model of scikit-learn:\n",
        "\n",
        "This uses a linear function and the ordinary least squares method.\n",
        "\n",
        "*comment: yes, this is pretty much the same as using `curve_fit` from `scipy` with a linear fit function like you did in the good old lab excercise days*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsRLMNmki0Ih"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHTGgwmDi0Il"
      },
      "source": [
        "OK, what is the result of the fit?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9NuZmTGi0In"
      },
      "source": [
        "# The coefficients\n",
        "print('Coefficients: \\n', lr.coef_)\n",
        "# The intercept\n",
        "print('Intercept: \\n', lr.intercept_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nbORmlOi0Is"
      },
      "source": [
        "OK, let's plot this linear function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3pPPp0ai0It"
      },
      "source": [
        "plt.scatter(X_test, y_test,  color='blue')\n",
        "plt.plot(X_test, y_pred, color='red', linewidth=3)\n",
        "plt.xlabel('Head size (cm$^3$)')\n",
        "plt.ylabel('Brain weight (grams)');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYCD0W1wi0Ix"
      },
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYkXqiKPi0Iy"
      },
      "source": [
        "How do we know if the fit was good? We need to define a performance measure. One way is to calculate the **Coefficient of determination**, denoted R^2. It is the proportion of the variance in the dependent variable that is predictable from the independent variables. It is calculated the following way:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5ogTiQai0Iz"
      },
      "source": [
        " <img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/eef0fc7006ba5f7df32eceeba7f1c5271e0100af\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtwbNrVyi0I0"
      },
      "source": [
        "sum_of_squares = ((y_test - y_pred) ** 2).sum()\n",
        "res_sum_of_squares = ((y_test - y_test.mean()) ** 2).sum()\n",
        "r2_score = 1 - (sum_of_squares / res_sum_of_squares)\n",
        "print('R2 score: %.2f' % r2_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqhUbtLGi0I4"
      },
      "source": [
        "It ranges from 0 to 1 and values close to 1 means a good agreement. Luckily, scikit-learn has several performance measures for [regression (metrics)](http://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics) already included."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msApu3yxi0I5"
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
        "# The mean squared error\n",
        "print(\"Mean absolute error: %.2f\" % mean_absolute_error(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkFotwTdi0I9"
      },
      "source": [
        "# 2 Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB3QaiFZi0I-"
      },
      "source": [
        "## The Iris dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiNeufOri0I_"
      },
      "source": [
        "### Task 3: The Iris flower dataset is stored in file **`dataset_iris.txt`**. Read in the dataset using a **`pandas`** `DataFrame` and have a look at the first entries.\n",
        "*hints*:\n",
        "- look what you did for the first data inspection in Task 1\n",
        "- what is the separator in the iris dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJsIW77hi0JA"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSohfKd2i0JH"
      },
      "source": [
        "We now need to create a 150x4 design matrix containing only our feature values. In order to do that, we need to strip the class column from the dataset. We use the [**`iloc`**](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iloc.html) function for that:\n",
        "\n",
        "> `DataFrame.iloc`\n",
        ">\n",
        "> Purely integer-location based indexing for selection by position.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRI-pt0hi0JI",
        "scrolled": true
      },
      "source": [
        "X = df.iloc[:, :4]\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XimWllPi0JM"
      },
      "source": [
        "And now we get 150$\\times$4 numpy array (design matrix) by using the values function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHfu7r02i0JO"
      },
      "source": [
        "X = X.values\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlOXZEfBi0JR"
      },
      "source": [
        "However, we also need a numpy array containing the class labels in order to classify. Let's get the class column and create a numpy array out of it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHX8oUzFi0JS"
      },
      "source": [
        "y = df['class'].values\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vUo7M_hi0JW"
      },
      "source": [
        "We could also just inspect the targets by only looking at unique values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g31gE6fi0JX"
      },
      "source": [
        "np.unique(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaPRj_xUi0Jf"
      },
      "source": [
        "## Class label encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKDEkX-4i0Jh"
      },
      "source": [
        "We will now use the **`LabelEncoder`** class to convert the class labels into numerical labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmItMbUti0Ji"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "l_encoder = LabelEncoder()\n",
        "l_encoder.fit(y)\n",
        "l_encoder.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06qH4azGi0Jl"
      },
      "source": [
        "Simply, by using **`transform`**, we can convert it into numerical targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc3p1FKHi0Jm"
      },
      "source": [
        "y_enc = l_encoder.transform(y)\n",
        "y_enc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP6ghqFSi0Jr"
      },
      "source": [
        "Or just the unique values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE5XVE9Ei0Js"
      },
      "source": [
        "np.unique(y_enc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4h-7M8Fi0Jx"
      },
      "source": [
        "We can also convert it back by using **`inverse_transform`**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLBV0DE4i0Jy"
      },
      "source": [
        "np.unique(l_encoder.inverse_transform(y_enc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ttUYt27i0J2"
      },
      "source": [
        "## Scikit-learn's in-build datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn1LqjlFi0J3"
      },
      "source": [
        "Scikit-learn has also a couple of [in-build datasets](http://scikit-learn.org/stable/datasets/index.html). The iris dataset is part of it, which you can simply load:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDOmMHDFi0J4"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "print(iris['DESCR'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWXmrZVOi0J8"
      },
      "source": [
        "We get the feature design matrix by calling data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNZzG4Kyi0J-"
      },
      "source": [
        " iris.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oJkizNmi0KG"
      },
      "source": [
        "And the target array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmljccf5i0KH"
      },
      "source": [
        "iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L-IZu_pi0KL"
      },
      "source": [
        "## Test/train splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1OAvYbgi0KP"
      },
      "source": [
        "OK, now we need to split the dataset again in training and testing. Let's first assign the design matrix to X and the target to y:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdRJ0Jv1i0KR"
      },
      "source": [
        "X, y = iris.data[:, :2], iris.target\n",
        "# ! We only use 2 features for visual purposes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkgwS6vDi0KW"
      },
      "source": [
        "How many example do we have of each class?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBppV5VKi0KX"
      },
      "source": [
        "print('Class labels:', np.unique(y))\n",
        "print('Class proportions:', np.bincount(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKUJP3isi0Kb"
      },
      "source": [
        "### Task 4: Split the dataset in 40% testing and 60% training sets.\n",
        "- How many examples of each class do you expect in the training set?\n",
        "- How many are there? What happened?\n",
        "- What happens if you don't shuffle?\n",
        "- Can you create datasets in which each class is equally distributed?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-65bkHVi0Kd",
        "scrolled": false
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiE7DOodi0Kq"
      },
      "source": [
        "### Task 5: Plot the sepal length vs the sepal width of the training set for the different classes in a scatter plot. You can set different colors for the classes with `c=y_train`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbKsWlxoi0Kr"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5bgYxwKi0Ku"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQkk8A5vi0Kv"
      },
      "source": [
        "Let's perform a classification using logistic regression:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi049nKJi0Kw"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(solver='newton-cg',\n",
        "                        multi_class='multinomial',\n",
        "                        random_state=42)\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZA8cd2Qi0Kz"
      },
      "source": [
        "OK, how do we evaluate the classification? We can chose one of the [classification performance measures](http://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7wE2jhPi0K0"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
        "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
        "print(\"Precision: %.2f\" % precision_score(y_test, y_pred, average='weighted'))\n",
        "print(\"Recall: %.2f\" % recall_score(y_test, y_pred, average='weighted'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOkSsLeRi0K2"
      },
      "source": [
        "Or we use the classification report function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEZna1nUi0K3"
      },
      "source": [
        "print('Classification Report:\\n', classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJNF655Bi0K6"
      },
      "source": [
        "Finally, we would like to plot the decision regions and our data in order to see how the classifier categorized the events. We have highlighted the test data."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gwmX4tKL7_4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Technicality) When running on Google Colab, we first need to update the *mlxtend* package, as Colab's default version of the packages is outdated:"
      ],
      "metadata": {
        "id": "B0QC6nTV8Atq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install mlxtend --upgrade  #this needs to be run only once and will install the most recent version of the mlxtend package"
      ],
      "metadata": {
        "id": "Aftd74q08ARt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfRnnab_i0K7"
      },
      "source": [
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "plot_decision_regions(X=X, y=y, clf=lr, X_highlight=X_test, legend=2)\n",
        "plt.xlabel('sepal length [cm]')\n",
        "plt.xlabel('sepal width [cm]');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jubkd-kAi0K9"
      },
      "source": [
        "## K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMY5bYMCi0K-"
      },
      "source": [
        "### Task 6 (Bonus): Perform a classification using [K-nearest neighbors classifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), evaluate the performance and show the decision regions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArLPd6Ayi0K_"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}